{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often not only want to see whats happening during computation, but intervene and edit the flow of information.\n",
    "\n",
    "In this example, we create a tensor of noise to add to the hidden states. We then add it, use the assigment `=` operator to update the tensors of `.output[0][:]` with these new noised values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "\n",
    "model = LanguageModel('gpt2', device_map='cuda')\n",
    "\n",
    "with model.trace('The Eiffel Tower is in the city of') as tracer:\n",
    "\n",
    "        hidden_states_pre = model.transformer.h[-1].output[0].clone().save()\n",
    "\n",
    "        noise = (0.001**0.5)*torch.randn(hidden_states_pre.shape)\n",
    "\n",
    "        model.transformer.h[-1].output[0][:] = hidden_states_pre + noise\n",
    "\n",
    "        hidden_states_post = model.transformer.h[-1].output[0].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't assign a NoneType to a torch.meta.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m noise \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(hidden_states_pre\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m][:] \u001b[38;5;241m=\u001b[39m hidden_states_pre \u001b[38;5;241m+\u001b[39m noise\n\u001b[0;32m---> 14\u001b[0m hidden_states_pre\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# hidden_states_post = model.transformer.h[-1].output[0].save()\u001b[39;00m\n",
      "File \u001b[0;32m~/nnsight/src/nnsight/contexts/Runner.py:42\u001b[0m, in \u001b[0;36mRunner.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"On exit, run and generate using the model whether locally or on the server.\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_server()\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m hidden_states_pre \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m noise \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(hidden_states_pre\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m hidden_states_pre \u001b[38;5;241m+\u001b[39m noise\n\u001b[1;32m     14\u001b[0m hidden_states_pre\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# hidden_states_post = model.transformer.h[-1].output[0].save()\u001b[39;00m\n",
      "File \u001b[0;32m~/nnsight/src/nnsight/tracing/Proxy.py:79\u001b[0m, in \u001b[0;36mProxy.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Union[Proxy, Any], value: Union[Proxy, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetitem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nnsight/src/nnsight/tracing/Graph.py:137\u001b[0m, in \u001b[0;36mGraph.add\u001b[0;34m(self, target, value, args, kwargs, name)\u001b[0m\n\u001b[1;32m    133\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_proxy_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_proxy_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't assign a NoneType to a torch.meta.FloatTensor"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch \n",
    "\n",
    "model = LanguageModel('gpt2', device_map='cuda')\n",
    "\n",
    "with model.trace('The Eiffel Tower is in the city of') as tracer:\n",
    "    \n",
    "    hidden_states_pre = model.transformer.h[-1].output[0]\n",
    "\n",
    "    noise = (0.001**0.5)*torch.randn(hidden_states_pre.shape)\n",
    "\n",
    "    model.transformer.h[-1].output[0][:] = hidden_states_pre + noise\n",
    "\n",
    "    hidden_states_pre.clone().save()\n",
    "\n",
    "    # hidden_states_post = model.transformer.h[-1].output[0].save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the change in the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.0197e-03, -1.1157e-01, -1.3560e-01,  ..., -9.5050e-01,\n",
      "           1.1737e-01, -1.0768e+00],\n",
      "         [ 8.7405e+00,  2.8481e+00,  5.2863e+00,  ..., -8.0872e+00,\n",
      "           1.2464e+00, -2.8597e+00],\n",
      "         [ 3.0816e-01,  4.6882e+00, -3.6241e+00,  ...,  2.5548e-01,\n",
      "          -2.5845e+00,  3.2085e+00],\n",
      "         ...,\n",
      "         [ 2.1914e+00,  6.8865e+00,  3.8589e+00,  ...,  7.3585e-02,\n",
      "          -1.9566e+00,  5.9064e+00],\n",
      "         [-4.0466e-01,  7.4140e+00, -9.3035e+00,  ...,  2.0717e+00,\n",
      "          -2.7665e+00,  5.0897e-01],\n",
      "         [ 6.5553e+00,  1.7157e+00,  4.7861e+00,  ...,  7.6273e+00,\n",
      "           3.0340e+00,  2.0660e+00]]], device='cuda:0')\n",
      "tensor([[[ 8.0197e-03, -1.1157e-01, -1.3560e-01,  ..., -9.5050e-01,\n",
      "           1.1737e-01, -1.0768e+00],\n",
      "         [ 8.7405e+00,  2.8481e+00,  5.2863e+00,  ..., -8.0872e+00,\n",
      "           1.2464e+00, -2.8597e+00],\n",
      "         [ 3.0816e-01,  4.6882e+00, -3.6241e+00,  ...,  2.5548e-01,\n",
      "          -2.5845e+00,  3.2085e+00],\n",
      "         ...,\n",
      "         [ 2.1914e+00,  6.8865e+00,  3.8589e+00,  ...,  7.3585e-02,\n",
      "          -1.9566e+00,  5.9064e+00],\n",
      "         [-4.0466e-01,  7.4140e+00, -9.3035e+00,  ...,  2.0717e+00,\n",
      "          -2.7665e+00,  5.0897e-01],\n",
      "         [ 6.5553e+00,  1.7157e+00,  4.7861e+00,  ...,  7.6273e+00,\n",
      "           3.0340e+00,  2.0660e+00]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states_pre)\n",
    "print(hidden_states_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
